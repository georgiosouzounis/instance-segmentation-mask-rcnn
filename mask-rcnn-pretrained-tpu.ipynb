{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mask-rcnn-pretrained-tpu.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1TpBjYhgzMQmOh6yCW7gMsO6YZM92X1bv","authorship_tag":"ABX9TyMpK4YFI8mgWhc/TAB4y3Ko"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6FnKLaTvKXKT"},"source":["# Instance Segmentation with Mask R-CNN with TPU support\n","\n","*by Georgios K. Ouzounis, June 22nd, 2021*\n","\n","In this notebook we will experiment with **instance segmentation** in still images using the **Mask R-CNN** model, trained on Cloud TPU. \n","\n","This is a slightly altered version of the original notebook posted by Google Research that can be found [here](https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/mask_rcnn/mask_rcnn_demo.ipynb#scrollTo=t_iHs_wm2Mhh)\n","\n","For each test image, the output set of predictions includes bounding boxes, labels and instance masks that are overlayed on the input. \n"]},{"cell_type":"markdown","metadata":{"id":"Hfbjzsv3hHGY"},"source":["## Instructions\n","<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Use a free Cloud TPU</h3>\n"," \n","On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator."]},{"cell_type":"markdown","metadata":{"id":"2gWyVilLhQ3n"},"source":["## Download the source code\n","Download the source code of the Mask R-CNN model from the **tensorflow/tpu/** github repo."]},{"cell_type":"code","metadata":{"id":"Cm9VdowHQJs2"},"source":["!git clone https://github.com/tensorflow/tpu/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1iql0DRhfvg"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"Jy-gw885QHuc"},"source":["import numpy as np\n","import cv2\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import sys\n","sys.path.insert(0, 'tpu/models/official')\n","sys.path.insert(0, 'tpu/models/official/mask_rcnn')\n","import coco_metric\n","from mask_rcnn.object_detection import visualization_utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kleTs8AwhyUZ"},"source":["## Load the COCO index mapping\n","This Colab uses a pretrained checkpoint of the Mask R-CNN model that is trained using the COCO dataset. Below is the mapping between the indices that the model predicts and the categories in text."]},{"cell_type":"code","metadata":{"id":"yr5wxOxZYR7O"},"source":["ID_MAPPING = {\n","    1: 'person',\n","    2: 'bicycle',\n","    3: 'car',\n","    4: 'motorcycle',\n","    5: 'airplane',\n","    6: 'bus',\n","    7: 'train',\n","    8: 'truck',\n","    9: 'boat',\n","    10: 'traffic light',\n","    11: 'fire hydrant',\n","    13: 'stop sign',\n","    14: 'parking meter',\n","    15: 'bench',\n","    16: 'bird',\n","    17: 'cat',\n","    18: 'dog',\n","    19: 'horse',\n","    20: 'sheep',\n","    21: 'cow',\n","    22: 'elephant',\n","    23: 'bear',\n","    24: 'zebra',\n","    25: 'giraffe',\n","    27: 'backpack',\n","    28: 'umbrella',\n","    31: 'handbag',\n","    32: 'tie',\n","    33: 'suitcase',\n","    34: 'frisbee',\n","    35: 'skis',\n","    36: 'snowboard',\n","    37: 'sports ball',\n","    38: 'kite',\n","    39: 'baseball bat',\n","    40: 'baseball glove',\n","    41: 'skateboard',\n","    42: 'surfboard',\n","    43: 'tennis racket',\n","    44: 'bottle',\n","    46: 'wine glass',\n","    47: 'cup',\n","    48: 'fork',\n","    49: 'knife',\n","    50: 'spoon',\n","    51: 'bowl',\n","    52: 'banana',\n","    53: 'apple',\n","    54: 'sandwich',\n","    55: 'orange',\n","    56: 'broccoli',\n","    57: 'carrot',\n","    58: 'hot dog',\n","    59: 'pizza',\n","    60: 'donut',\n","    61: 'cake',\n","    62: 'chair',\n","    63: 'couch',\n","    64: 'potted plant',\n","    65: 'bed',\n","    67: 'dining table',\n","    70: 'toilet',\n","    72: 'tv',\n","    73: 'laptop',\n","    74: 'mouse',\n","    75: 'remote',\n","    76: 'keyboard',\n","    77: 'cell phone',\n","    78: 'microwave',\n","    79: 'oven',\n","    80: 'toaster',\n","    81: 'sink',\n","    82: 'refrigerator',\n","    84: 'book',\n","    85: 'clock',\n","    86: 'vase',\n","    87: 'scissors',\n","    88: 'teddy bear',\n","    89: 'hair drier',\n","    90: 'toothbrush',\n","}\n","\n","#create a dictionary with class IDs mapped to the COCO labels \n","category_index = {k: {'id': k, 'name': ID_MAPPING[k]} for k in ID_MAPPING}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u6ThztY9jZVH"},"source":["## Get a sample image\n","\n","Use the **wget** command to download locally an image of your liking or mount your Google Drive and copy one locally"]},{"cell_type":"code","metadata":{"id":"2JnbyQdca2Qa"},"source":["# sample image used in the original Colab Notebook\n","!wget https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Kitano_Street_Kobe01s5s4110.jpg/2560px-Kitano_Street_Kobe01s5s4110.jpg -O test.jpg\n","image_path = 'test.jpg'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3V2k9SYIw6MY"},"source":["# sample image from the author's github repo\n","!wget https://github.com/georgiosouzounis/instance-segmentation-mask-rcnn/raw/main/data/newyork.jpg -O test.jpg\n","image_path = 'test.jpg'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1p7aiqTj4xI"},"source":["# read the image both as 3D numpy array (openCV) and as a serialized string \n","# for model compatibility\n","image = cv2.imread(image_path)\n","# convert the BGR order to RGB\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","# get the image width and height\n","width, height = image.shape[1], image.shape[0]\n"," \n","# serialization\n","with open(image_path, 'rb') as f:\n","  np_image_string = np.array([f.read()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rC4lmpVdbOz3"},"source":["# view the selected image\n","from google.colab.patches import cv2_imshow\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_1CEZTPkZGP"},"source":["## Create a Tensorflow session\n","\n","Create a Tensorflow session to run the inference. You can either connect to a TPU or a normal CPU backend."]},{"cell_type":"code","metadata":{"id":"Vl-0BOY6bhyB"},"source":["use_tpu = False #@param {type:\"boolean\"}\n","# if using the TPU runtime:\n","if use_tpu:\n","  import os\n","  import pprint\n","\n","  # assert the TPU address\n","  assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n","  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  print('TPU address is', TPU_ADDRESS)\n","\n","  # initialize a session\n","  session = tf.Session(TPU_ADDRESS, graph=tf.Graph())\n","  print('TPU devices:')\n","  pprint.pprint(session.list_devices())\n","# else if using the CPU runtime:\n","else:\n","  # initialize a session\n","  session = tf.Session(graph=tf.Graph())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HbDzreKilGTQ"},"source":["## Load the pretrained model\n","Load the COCO pretrained model from the public GCS bucket. Ignore the deprecation warnings as there is no immediate fix for using tensorflow2 togetehr with Mask R-CNN"]},{"cell_type":"code","metadata":{"id":"ipKvrUxQbppG"},"source":["# set the model directory here or on the line to the right\n","saved_model_dir = 'gs://cloud-tpu-checkpoints/mask-rcnn/1555659850' #@param {type:\"string\"}\n","\n","# load the model\n","# underscore _ is considered as \"I don't Care\" or \"Throwaway\" variable in Python. \n","_ = tf.saved_model.loader.load(session, ['serve'], saved_model_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aK0L8cFGmOoZ"},"source":["## Compute instance segmentation\n","\n","Run the inference and process the predictions returned by the model."]},{"cell_type":"code","metadata":{"id":"2Sepq7Hbbw9s"},"source":["# get the predictions by running the session created earlier\n","num_detections, detection_boxes, detection_classes, detection_scores, detection_masks, image_info = session.run(\n","    ['NumDetections:0', 'DetectionBoxes:0', 'DetectionClasses:0', 'DetectionScores:0', 'DetectionMasks:0', 'ImageInfo:0'],\n","    feed_dict={'Placeholder:0': np_image_string})\n","\n","# remove axes of length 1 in each of the numpy arrays returned at the end of the session.\n","num_detections = np.squeeze(num_detections.astype(np.int32), axis=(0,))\n","detection_boxes = np.squeeze(detection_boxes * image_info[0, 2], axis=(0,))[0:num_detections]\n","detection_scores = np.squeeze(detection_scores, axis=(0,))[0:num_detections]\n","detection_classes = np.squeeze(detection_classes.astype(np.int32), axis=(0,))[0:num_detections]\n","instance_masks = np.squeeze(detection_masks, axis=(0,))[0:num_detections]\n","\n","# extract the bounding box endpoints from the detection_boxes array\n","ymin, xmin, ymax, xmax = np.split(detection_boxes, 4, axis=-1)\n","# convert each bbox endpoint array to the desired format [x_start, y_start, width, height]\n","processed_boxes = np.concatenate([xmin, ymin, xmax - xmin, ymax - ymin], axis=-1)\n","\n","# generates the segmentation result from an instance mask and its bbox for each detection\n","segmentations = coco_metric.generate_segmentation_from_masks(instance_masks, processed_boxes, height, width)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"65L-GAumrR_0"},"source":["## Visualize the detection results\n"]},{"cell_type":"code","metadata":{"id":"b_1vbAdNb7ic"},"source":["# set  the max number of boxes to draw and the detection confidence threshold\n","max_boxes_to_draw = 50   #@param {type:\"integer\"}\n","min_score_thresh = 0.5    #@param {type:\"slider\", min:0, max:1, step:0.01}\n","\n","# create the ouput image with bboxes, labels and segments imprinted\n","image_with_detections = visualization_utils.visualize_boxes_and_labels_on_image_array(\n","    image,\n","    detection_boxes,\n","    detection_classes,\n","    detection_scores,\n","    category_index,\n","    instance_masks=segmentations,\n","    use_normalized_coordinates=False,\n","    max_boxes_to_draw=max_boxes_to_draw,\n","    min_score_thresh=min_score_thresh)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmBO0N9evWr_"},"source":["# dispaly the resulting image\n","cv2_imshow(image_with_detections)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sno_EglDIyyd"},"source":["## Training Mask R-CNN on Cloud TPU\n","\n","To train the Mask R-CNN on custom data on Cloud TPU you may wish to consult [this tutorial](https://cloud.google.com/tpu/docs/tutorials/mask-rcnn) from Google Research. Please do note that the tutorial uses billable components of Google Cloud, including:\n","- Compute Engine\n","- Cloud TPU\n","- Cloud Storage\n"]}]}