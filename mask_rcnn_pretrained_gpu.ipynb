{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask-rcnn-pretrained-gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIDafmcXSNns"
      },
      "source": [
        "# Instance Segmentation with Mask R-CNN with GPU support\n",
        "\n",
        "*by Georgios K. Ouzounis, June 22nd, 2021*\n",
        "\n",
        "In this notebook we will experiment with instance segmentation in still images using the Mask R-CNN model, trained on GPU.\n",
        "\n",
        "This is a slightly altered version of the original notebook posted by [Matterport, Inc](https://matterport.com/) that can be [found here](https://github.com/matterport/Mask_RCNN).\n",
        "\n",
        "For each test image, the output set of predictions includes bounding boxes, labels and instance masks that are overlayed on the input. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shQBS8Cd7qMr"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WheSLo7T3Bkh"
      },
      "source": [
        "Mask R-CNN has certain outdated dependencies and we need to re-install some packages.\n",
        "\n",
        "The first is Tensorflow, which in the case of Google Colab is available in different versions. Using TensorFlow 1.x requires downgrading h5py too. This, after installation, will prompt for a restart of the Runtime. Click the button to confirm and do not re-execute the ```pip install```.\n",
        "\n",
        "You may ignore the different dependency erros as the packages they refer to are not relevant for this exercise.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8Q30u71pRF"
      },
      "source": [
        "!pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tVS_x0xOTcq"
      },
      "source": [
        "If you wish to review the configuration of the newly installed HDF5 execute the command below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MNvFdF3EXe"
      },
      "source": [
        "!h5cc -showconfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uB4cF2D7t_5"
      },
      "source": [
        "## Clone the repo from GitHub\n",
        "\n",
        "Get a local copy of the Matterport repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttgRcakjuQ4P"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUyEWg3PO6YU"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhsm2XmHPHVp"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyO_T7_h7xHq"
      },
      "source": [
        "# Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3TqaKKzukha"
      },
      "source": [
        "import os \n",
        "os.chdir('Mask_RCNN/samples')\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRNzMHg08Uvn"
      },
      "source": [
        "# Create & configure an Inference Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-SLKOPeu0PY"
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-C88yeKvWaa"
      },
      "source": [
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEErre3vY5m"
      },
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "CLASS_NAMES = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PTdUjUC76A8"
      },
      "source": [
        "## Model inference and visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLWTZfVfVnQl"
      },
      "source": [
        "### Load a test image\n",
        "\n",
        "option 1: get a test image from the author's github account\n",
        "\n",
        "<img src=\"https://github.com/georgiosouzounis/instance-segmentation-mask-rcnn/raw/main/data/manhattan.jpg\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS4AF1HfXmGq"
      },
      "source": [
        "!wget https://github.com/georgiosouzounis/instance-segmentation-mask-rcnn/raw/main/data/manhattan.jpg -O /content/test_image.jpg\n",
        "test_img_path = \"/content/test_image.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUu4NrZX8p4"
      },
      "source": [
        "option 2: get an image for the test set of the Matterport repo:\n",
        "\n",
        "<img src=\"https://github.com/matterport/Mask_RCNN/raw/master/images/8829708882_48f263491e_z.jpg\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs_B0A0bYy_j"
      },
      "source": [
        "test_img_path = \"/content/Mask_RCNN/images/8829708882_48f263491e_z.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHrgwpTgYjon"
      },
      "source": [
        "option 3: use **wget** to download an image from the web or mount your Google Drive and copy one locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib0QQwd4ZEeu"
      },
      "source": [
        "### Read the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ill2tEP5ZIpH"
      },
      "source": [
        "# read the image\n",
        "image = cv2.imread(test_img_path)\n",
        "# convert the BGR order to RGB\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV90iPeHZcx4"
      },
      "source": [
        "### Model inference and result visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBaILxtBPyBu"
      },
      "source": [
        "# model inference\n",
        "results = model.detect([image], verbose=0)\n",
        "\n",
        "# result visualization\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            CLASS_NAMES, r['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjY0vCc0dGuS"
      },
      "source": [
        "## Custom visualization with score filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3IBoPS_g3nh"
      },
      "source": [
        "Set the score threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6bbhQGXfb7r"
      },
      "source": [
        "score_threshold = 0.99    #@param {type:\"slider\", min:0, max:1, step:0.01}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ-u4I4wg8UK"
      },
      "source": [
        "Define random class colors. The method comes from the Matterport repo and ensures that generated colors are visually distinct.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4e/HSV_color_solid_cylinder.png\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atiakCTKhIbt"
      },
      "source": [
        "import colorsys\n",
        "\n",
        "# create a Hue-Saturation-Value list with saturation and value preset to 1\n",
        "# changes in hue are essentially changes in color.     \n",
        "hsv = [(i / len(CLASS_NAMES), 1, 1.0) for i in range(len(CLASS_NAMES))]\n",
        "\n",
        "# in what follows:\n",
        "# - the lambda function is the converter of an HSV triplet to RGB;\n",
        "# - the map (i.e. r = map(func, seq)) applies this function to the sequence hsv;\n",
        "# - in Python 3, map() returns an iterator. To get the results in a list we use \n",
        "#   the list() function \n",
        "CLASS_COLORS = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "\n",
        "# shuffle the generated colors so that there is no correlation with the class IDs\n",
        "random.seed(42)\n",
        "random.shuffle(CLASS_COLORS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UCOApGXmKLt"
      },
      "source": [
        "Imprint the masks of the detected objects into the image  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYXwjDZAmbrk"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI7Jbkvndrm1"
      },
      "source": [
        "output = image.copy()\n",
        "output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# loop through the detected objects\n",
        "for i in range(0, r[\"rois\"].shape[0]):\n",
        "  score = r[\"scores\"][i]\n",
        "  # filter the detections based on score\n",
        "  if score > score_threshold:\n",
        "    # get the class ID for the current detection\n",
        "    classID = r[\"class_ids\"][i]\n",
        "    # get the mask for teh current detection \n",
        "    mask = r[\"masks\"][:, :, i]\n",
        "    # get the color assigned to the detected class\n",
        "    color = CLASS_COLORS[classID][::-1]\n",
        "    # imprint the mask in the image \n",
        "    output = visualize.apply_mask(output, mask, color, alpha=0.5)\n",
        "# display the result\n",
        "cv2_imshow(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTb9zE8Rd73D"
      },
      "source": [
        "# loop through the predicted scores\n",
        "for i in range(0, len(r[\"scores\"])):\n",
        "  # get the score (predicted probability)\n",
        "  score = r[\"scores\"][i]\n",
        "  # filter the detections based on score\n",
        "  if score > score_threshold:\n",
        "    # get the bounding box (bbox)\n",
        "    (bbox_start_y, bbox_start_x, bbox_end_y, bbox_end_x) = r[\"rois\"][i]\n",
        "    # get the class ID\n",
        "    classID = r[\"class_ids\"][i]\n",
        "    # get the label\n",
        "    label = CLASS_NAMES[classID]\n",
        "    # get the class color\n",
        "    color = [int(c) for c in np.array(CLASS_COLORS[classID]) * 255]\n",
        "    # draw the bounding box\n",
        "    cv2.rectangle(output, (bbox_start_x, bbox_start_y), (bbox_end_x, bbox_end_y), color, 2)\n",
        "    # print the object class label and score \n",
        "    text = \"{}: {:.3f}\".format(label, score)\n",
        "    # make sure teh starting y-coord of the text is within the image\n",
        "    y = bbox_start_y - 10 if bbox_start_y - 10 > 10 else bbox_startY + 10\n",
        "    cv2.putText(output, text, (bbox_start_x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "# display the result\n",
        "cv2_imshow(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15MmM7qjP4ZO"
      },
      "source": [
        "## Selective visualization\n",
        "\n",
        "Use the function below to extract the detected object(s) from the input image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHa0sU0oaa9E"
      },
      "source": [
        "def instance_extraction(image, r):\n",
        "  for i in range(0, len(r[\"scores\"])):\n",
        "    # get the score (predicted probability)\n",
        "    score = r[\"scores\"][i]\n",
        "    # filter the detections based on score\n",
        "    if score > score_threshold:\n",
        "      # get the mask\n",
        "      mask = r['masks'][:,:,i]\n",
        "      # convert mask to a 3 channel image of type UCHARx3\n",
        "      mask = np.stack((mask,)*3, axis=-1)\n",
        "      mask = mask.astype('uint8')\n",
        "      # create a white background image\n",
        "      # mask is binary [0,1] so to make usable multiply it by 255\n",
        "      bg = 255 - mask*255\n",
        "      # mask the selected detections\n",
        "      masked_img = image*mask\n",
        "      # add the white background\n",
        "      result = masked_img + bg\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzLmfWZdvg3E"
      },
      "source": [
        "segmentation = instance_extraction(image, r)\n",
        "plt.subplots(1, figsize=(16, 16))\n",
        "plt.axis('off')\n",
        "plt.imshow(np.concatenate([image, segmentation], axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}